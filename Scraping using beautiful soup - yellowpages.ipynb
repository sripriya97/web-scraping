{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5323f47",
   "metadata": {},
   "source": [
    "## Scrape Yellowpages for extracting information about Pizzeria's in San Francisco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6d738",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad169949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup \n",
    "import pymongo\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3024b99",
   "metadata": {},
   "source": [
    "### Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdriver ():\n",
    "    path=r'chromedriver.exe'\n",
    "    #driver = webdriver.Chrome(executable_path='/Users/Sripriya Srinivasan/Downloads/chromedriver_win32/chromedriver')\n",
    "    driver = webdriver.Chrome(executable_path=path)\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.set_script_timeout(120)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePage(fname,content):\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(str(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file (name):\n",
    "    HTMLFile = open(name, \"rb\")\n",
    "    htmlfiledata = HTMLFile.read()\n",
    "    return BeautifulSoup(htmlfiledata, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mongodb (db_name, collection_name):\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWebsiteData (url):\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url,headers=headers)\n",
    "        # Create a beautifulsoup object \n",
    "        return BeautifulSoup(page.text, 'lxml')\n",
    "    except :\n",
    "        print(\"Error connecting to website\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateData (sr,new_val):\n",
    "    collection = connect_mongodb (\"pizzeria\", \"sf_pizzerias\")\n",
    "    myquery = { \"search rank\": sr }\n",
    "    newvalues = { \"$set\": new_val }\n",
    "    collection.update_many(myquery, newvalues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cc7b8f6",
   "metadata": {},
   "source": [
    "### Task 1 \n",
    "Search on yellowpages.com for the top 30 “Pizzeria” in San Francisco. Save the search result page to disk, “sf_pizzeria_search_page.htm”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4():\n",
    "    yp_url = \"https://www.yellowpages.com/search?search_terms=pizzeria&geo_location_terms=San%20Francisco%2C%20CA\"\n",
    "    pizzeria = loadWebsiteData(yp_url)\n",
    "    writePage(\"sf_pizzeria_search_page.htm\",pizzeria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a5062d2",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Open the search result page saved in Task 3 and parses out all shop information (search rank, name, linked URL [this store’s YP URL], star rating If It Exists, number of reviews IIE, TripAdvisor rating IIE, number of TA reviews IIE, “$” signs IIE, years in business IIE, review IIE, and amenities IIE).  Please be sure to skip all “Ad” results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q5():\n",
    "    search_soup = read_file(\"sf_pizzeria_search_page.htm\")\n",
    "    results = search_soup.select(\"div.search-results.organic > div.result\")\n",
    "    base_url = \"https://www.yellowpages.com\"\n",
    "\n",
    "    pizzeria_docs = []\n",
    "\n",
    "    for result in results:\n",
    "        amenities_list = []\n",
    "        search_rank = re.search(\"\\d+\",result.find_all(\"h2\", {\"class\": \"n\"})[0].text).group()\n",
    "        name = result.select(\"h2.n > a\")[0].text\n",
    "        url = base_url + result.select(\"h2.n > a\")[0]['href']\n",
    "        star = result.find(\"a\",{\"class\":\"rating hasExtraRating\"})\n",
    "        ratings = result.find(\"div\",{\"class\":\"ratings\"})\n",
    "\n",
    "        star_rating = None\n",
    "        star_review = None\n",
    "        if(star is not None):\n",
    "            star_rating = star.find(\"div\")['class'][1]\n",
    "            star_review = star.find(\"span\").text\n",
    "\n",
    "        ta_rating = None\n",
    "        ta_reviews = None\n",
    "        if(ratings is not None):\n",
    "            try:\n",
    "                ta = json.loads(ratings[\"data-tripadvisor\"])\n",
    "            except:\n",
    "                ta=None\n",
    "            if(ta is not None):\n",
    "                ta_rating = ta.get('rating')\n",
    "                ta_reviews = ta.get('count')\n",
    "\n",
    "        price = result.find(\"div\",{\"class\":\"price-range\"}).text if result.find(\"div\",{\"class\":\"price-range\"}) is not None else result.find(\"div\",{\"class\":\"price-range\"})\n",
    "\n",
    "        years_in_business = result.find(\"div\",{\"class\":\"years-in-business\"})\n",
    "        years = None\n",
    "        if(years_in_business is not None):\n",
    "            years = years_in_business.findChildren(\"div\",{\"class\":\"number\"})[0].text\n",
    "\n",
    "        review_html = result.find(\"p\",{\"class\":\"body with-avatar\"})\n",
    "        review = review_html.text if review_html is not None else review_html\n",
    "\n",
    "        amenities = result.find(\"div\",{\"class\":\"amenities-info\"})\n",
    "        if(amenities is not None):\n",
    "            amenities_span = amenities.findChildren(\"span\")\n",
    "            for amenity in amenities_span:\n",
    "                amenities_list.append(amenity.text)\n",
    "\n",
    "        pizzeria = {\"search rank\":search_rank,\n",
    "                   \"name\":name,\n",
    "                   \"url\":url,\n",
    "                   \"star rating\":{\"rating\":star_rating, \"review count\":star_review},\n",
    "                   \"ta rating\":{\"rating\":ta_rating,\"review count\":ta_reviews},\n",
    "                   \"price\":price,\n",
    "                   \"years in business\":years,\n",
    "                   \"reviews\":review,\n",
    "                   \"amenities\":amenities_list}\n",
    "        pizzeria_docs.append(pizzeria)\n",
    "        print(pizzeria)\n",
    "        print()\n",
    "    return pizzeria_docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pizzeria_docs = q5()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c6c91fc",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Create a MongoDB collection called “sf_pizzerias” that stores all the extracted shop information, one document for each shop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_pizzerias = connect_mongodb('pizzeria','sf_pizzerias')\n",
    "sf_pizzerias.insert_many(pizzeria_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbf88a39",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Read all URLs stored in “sf_pizzerias” and download each shop page.  Store the page to disk, “sf_pizzerias_[SR].htm” (replace [SR] with the search rank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f944875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q7():\n",
    "    for doc in pizzeria_docs:\n",
    "        url = doc['url']\n",
    "        sr = doc['search rank']\n",
    "        time.sleep(2)\n",
    "        soup = loadWebsiteData(url)\n",
    "        fname = \"sf_pizzerias_\"+str(sr)+\".htm\"\n",
    "        time.sleep(2)\n",
    "        writePage(fname,soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "q7()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9aab19e8",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Read the 30 shop pages saved in Task 6 and parse each shop’s address, phone number, and website.\n",
    "Use https://positionstack.com/Links API to query each shop address’ geolocation (long, lat) and update each shop document on the MongoDB collection “sf_pizzerias” to contain the shop’s address, phone number, website, and geolocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q9(address):\n",
    "    url = \"http://api.positionstack.com/v1/forward?access_key=b16e55d0611eb7e98ed44d6e8331f40b&query=\" + address + \"&output=json\"\n",
    "    data = loadWebsiteData(url)\n",
    "    datajson = json.loads(data.select(\"p\")[0].text)\n",
    "    latitude = \"Not found\"\n",
    "    longitude = \"Not found\"\n",
    "    if 'data' in datajson:\n",
    "        latitude = datajson['data'][0]['latitude']\n",
    "        longitude = datajson['data'][0]['longitude']\n",
    "    return {\"latitude\":latitude, \"longitude\":longitude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q8and9():\n",
    "    for i in range(1,31):\n",
    "        fname = \"sf_pizzerias_\"+str(i)+\".htm\"\n",
    "        soup = read_file(fname)\n",
    "        print(fname)\n",
    "        address = \"Info Missing\"\n",
    "        geolocation = \"Info Missing\"\n",
    "        if (len(soup.select(\"span.address\"))>0):\n",
    "            address = soup.select(\"span.address\")[0].text\n",
    "            geolocation = q9(address)\n",
    "        ph_num = soup.select(\"a.phone.dockable > strong\")[0].text if len(soup.select(\"a.phone.dockable > strong\"))>0 else \"Info Missing\"\n",
    "        website = soup.select(\"a.website-link.dockable\")[0]['href'] if len(soup.select(\"a.website-link.dockable\"))>0 else \"Info Missing\"\n",
    "        extra_info = {\"address\":address, \"geolocation\":geolocation, \"phone_number\":ph_num, \"website\":website}\n",
    "        print(extra_info)\n",
    "        print()\n",
    "        updateData(str(i),extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "q8and9()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
